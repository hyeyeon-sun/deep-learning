import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()
import numpy as np
 
x_data = [[1, 2, 1],
          [1, 3, 2],
          [1, 3, 4],
          [1, 5, 5],
          [1, 7, 5],
          [1, 2, 5],
          [1, 6, 6],
          [1, 7, 7]]
y_data = [[0, 0, 1],
          [0, 0, 1],
          [0, 0, 1],
          [0, 1, 0],
          [0, 1, 0],
          [0, 1, 0],
          [1, 0, 0],
          [1, 0, 0]]
 
# Evaluation our model using this test dataset
x_test = [[2, 1, 1],
          [3, 1, 2],
          [3, 3, 4]]
y_test = [[0, 0, 1],
          [0, 0, 1],
          [0, 0, 1]]
 
X = tf.placeholder("float", [None, 3])
Y = tf.placeholder("float", [None, 3])
 
W = tf.Variable(tf.random_normal([3, 3]))
b = tf.Variable(tf.random_normal([3]))
 
# tf.nn.softmax computes softmax activations
# softmax = exp(logits) / reduce_sum(exp(logits), dim)
hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)
 
# Cross entropy cost/loss
cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))
# Try to change learning_rate to small numbers
optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)
 
# Correct prediction Test model
prediction = tf.argmax(hypothesis, 1)
is_correct = tf.equal(prediction, tf.argmax(Y, 1))
accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))
 
# Launch graph
with tf.Session() as sess:
    # Initialize TensorFlow variables
    sess.run(tf.global_variables_initializer())
 
    for step in range(201):
        cost_val, W_val, _ = sess.run([cost, W, optimizer], feed_dict={X: x_data, Y: y_data})
        print(step, cost_val, W_val)
 
    # predict
    print("Prediction:", sess.run(prediction, feed_dict={X: x_test}))
    # Calculate the accuracy
    print("Accuracy: ", sess.run(accuracy, feed_dict={X: x_test, Y: y_test}))
 
'''
learning rate : 2.0
0 2.481961 [[ 0.808544   1.3013937 -1.6374297]
 [-0.5847428  1.9140662 -4.0825534]
 [ 1.1045763  2.8628712 -1.618924 ]]
1 18.824436 [[ 1.3084809   0.05145693 -0.8874297 ]
 [ 2.66513    -3.3358064  -2.0825534 ]
 [ 4.354512   -2.137064    0.13107598]]
2 nan [[nan nan nan]
 [nan nan nan]
 [nan nan nan]]
3 nan [[nan nan nan]
 [nan nan nan]
 [nan nan nan]]
...
200 nan [[nan nan nan]
 [nan nan nan]
 [nan nan nan]]
Prediction: [0 0 0]
Accuracy:  0.0
너무 클 때 : 값이 발산.
---------------------
learing rate : 1e-10
0 2.556754 [[ 0.72504026 -0.51842254  1.6360186 ]
 [ 0.47661072  0.02948774  0.3603019 ]
 [ 1.9966121   1.9674194   1.5864257 ]]
1 2.556754 [[ 0.72504026 -0.51842254  1.6360186 ]
 [ 0.47661072  0.02948774  0.3603019 ]
 [ 1.9966121   1.9674194   1.5864257 ]]
2 2.556754 [[ 0.72504026 -0.51842254  1.6360186 ]
 [ 0.47661072  0.02948774  0.3603019 ]
 [ 1.9966121   1.9674194   1.5864257 ]]
3 2.556754 [[ 0.72504026 -0.51842254  1.6360186 ]
 [ 0.47661072  0.02948774  0.3603019 ]
 [ 1.9966121   1.9674194   1.5864257 ]]
4 2.556754 [[ 0.72504026 -0.51842254  1.6360186 ]
 [ 0.47661072  0.02948774  0.3603019 ]
 [ 1.9966121   1.9674194   1.5864257 ]]
 ...
 
196 2.556754 [[ 0.72504026 -0.51842254  1.6360186 ]
 [ 0.47661072  0.02948774  0.3603019 ]
 [ 1.9966121   1.9674194   1.5864257 ]]
197 2.556754 [[ 0.72504026 -0.51842254  1.6360186 ]
 [ 0.47661072  0.02948774  0.3603019 ]
 [ 1.9966121   1.9674194   1.5864257 ]]
198 2.556754 [[ 0.72504026 -0.51842254  1.6360186 ]
 [ 0.47661072  0.02948774  0.3603019 ]
 [ 1.9966121   1.9674194   1.5864257 ]]
199 2.556754 [[ 0.72504026 -0.51842254  1.6360186 ]
 [ 0.47661072  0.02948774  0.3603019 ]
 [ 1.9966121   1.9674194   1.5864257 ]]
200 2.556754 [[ 0.72504026 -0.51842254  1.6360186 ]
 [ 0.47661072  0.02948774  0.3603019 ]
 [ 1.9966121   1.9674194   1.5864257 ]]
 Prediction: [0 2 0]
Accuracy:  0.33333334
너무 작을 때 : cost 값이 갈수록 변하지 않고 머뭄
------------------------------------------
learning rate = 0.1
0 7.816813 [[ 2.1723878   0.07433416 -1.2341454 ]
 [ 0.21955611  0.5635566   0.02322271]
 [-1.9038371   0.72041076  0.8329903 ]]
1 5.7353907 [[ 2.1945105   0.0164572  -1.1983912 ]
 [ 0.37612408  0.31218928  0.11802205]
 [-1.7443941   0.4801206   0.91383743]]
2 4.0159507 [[ 2.2119024  -0.01537871 -1.1839471 ]
 [ 0.52209353  0.17413075  0.11011114]
 [-1.5908499   0.35747302  0.88294077]]
3 3.3536198 [[ 2.2238827  -0.0203157  -1.1909903 ]
 [ 0.654227    0.16626558 -0.01415713]
 [-1.4458715   0.36146015  0.7339753 ]]
4 2.790309 [[ 2.2314658  -0.04597655 -1.1729126 ]
 [ 0.772606    0.0397604  -0.00603092]
 [-1.3106072   0.24059848  0.7195727 ]]
 ...
 199 0.67208993 [[ 0.20719977 -0.25526592  1.0606424 ]
 [ 0.39176708  0.18911055  0.22545832]
 [ 0.13889554  0.14250961 -0.6318402 ]]
200 0.67086613 [[ 0.2019619  -0.25551403  1.0661284 ]
 [ 0.3921595   0.18955901  0.22461747]
 [ 0.14058895  0.14238301 -0.63340706]]
Prediction: [2 2 2]
Accuracy:  1.0
'''
